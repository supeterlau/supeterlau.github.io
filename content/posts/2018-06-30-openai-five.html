--- 
title: "OpenAI Five" 
date: 2018-06-30T00:54:31+08:00 
draft: false 
categories: [AI] 
tags: [OpenAI, DotA2] 
--- 

Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.

<!--more-->

<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>OpenAI Five</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="https://blog.openai.com/openai-five/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <meta property="og:site_name" content="OpenAI Blog" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="OpenAI Five" />
    <meta property="og:description" content="Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2." />
    <meta property="og:url" content="https://blog.openai.com/openai-five/" />
    <meta property="og:image" content="https://blog.openai.com/content/images/2018/06/dota-card-2.jpg" />
    <meta property="article:published_time" content="2018-06-25T14:00:10.000Z" />
    <meta property="article:modified_time" content="2018-06-25T20:53:45.000Z" />
    <meta property="article:publisher" content="https://www.facebook.com/openai.research" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="OpenAI Five" />
    <meta name="twitter:description" content="Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2." />
    <meta name="twitter:url" content="https://blog.openai.com/openai-five/" />
    <meta name="twitter:image" content="https://blog.openai.com/content/images/2018/06/dota-card-2.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="OpenAI" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="" />
    <meta name="twitter:site" content="@openai" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="675" />

    <link rel="alternate" type="application/rss+xml" title="OpenAI Blog" href="https://blog.openai.com/rss/" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <link rel="icon" href="https://blog.openai.com/assets/images/favicon/favicon.ico">
    <link rel="shortcut icon" href="https://blog.openai.com/assets/images/favicon/favicon.ico">
    <link rel="apple-touch-icon" href="https://blog.openai.com/assets/images/favicon/favicon.png">
    <link rel="stylesheet" type="text/css" href="https://blog.openai.com/assets/css/style.css?v=f5ebf2b765" />
    <meta name="twitter:card" content="summary_large_image">
    
</head>

<body class="post-template tag-hash-design-card-image">
    <main class="Main">
        <div class="MainContent">
            <article class="Post post tag-hash-design-card-image" id="openai-five">
                <header class="PostHeader">
                    <div class="PostHeader-background">
                        <svg class="icon" width="100%" height="100%" viewBox="0 0 330 418" preserveAspectRatio="none">
        </svg>
                        <div class="PostHeader-background-glare"></div>
                    </div>
                </header>
                <section class="PostContent post-content">
                    <div class="kg-card-markdown">
                </section>
                <div id="dota-5v5-hero-video">
                    <div class="Post__RobotsThatLearn__Video">
                        <a href="https://www.youtube.com/watch?v=eHipy_j29Xw" class="Post__RobotsThatLearn__Video-button"><span><strong>Watch Video</strong></span></a>
                        <div class="Post__IngredientsForRoboticsResearch__PlayerContainer">
                            <div class="Post__IngredientsForRoboticsResearch__Player">
                                <iframe class="no-fluidvids" width="100%" height="100%" src="https://www.youtube.com/embed/eHipy_j29Xw?rel=0&amp;showinfo=0&amp;enablejsapi=1&amp;color=white&amp;vq=hd1080" frameborder="0" allow="encrypted-media" allowfullscreen></iframe>
                            </div>
                        </div>
                    </div>
                </div>

                <section class="Post-inner PostContent post-content research-release-post" id="content">
                    <p>Our team of five neural networks, OpenAI Five, has started to <a href="#thegames">defeat</a> amateur human teams at <a href="http://www.dota2.com/play/">Dota 2</a>. While today we play with <a href="#restricted">restrictions</a>, we
                        aim to beat a team of top professionals at <a href="https://en.wikipedia.org/wiki/The_International_(Dota_2)">The International</a> in August subject only to a limited set of heroes. We may not succeed: Dota 2 is one of the most
                        popular and <a href="https://purgegamers.true.io/g/dota-2-guide">complex</a> esports games in the world, with creative and motivated professionals who <a href="https://venturebeat.com/2017/02/12/dota-evil-geniuses/">train</a> year-round
                        to earn part of Dota's annual $40M <a href="https://www.esportsearnings.com/history/2017/games">prize pool</a> (the largest of any esports game).</p>
                    <p>OpenAI Five plays 180 years worth of games against itself every day, learning via self-play. It trains using a scaled-up version of <a href="https://blog.openai.com/openai-baselines-ppo/">Proximal Policy Optimization</a> running on
                        256 GPUs and 128,000 CPU cores — a larger-scale version of the system we built to play the much-simpler <a href="https://blog.openai.com/dota-2/">solo variant</a> of the game last year. Using a separate <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/#lstm-networks">LSTM</a>                        for each hero and no human data, it learns recognizable strategies. This indicates that <a href="https://www.technologyreview.com/s/603501/10-breakthrough-technologies-2017-reinforcement-learning/">reinforcement learning</a> can
                        yield long-term planning with large but achievable scale — without fundamental advances, contrary to our own expectations upon starting the project.</p>
                    <p>To benchmark our progress, we'll host a match versus top players on July 28th. <a href="https://www.twitch.tv/openai">Follow</a> us on Twitch to view the live broadcast, or <a href="https://www.eventbrite.com/e/openai-five-benchmark-tickets-47144438284">request</a>                        an invite to attend in person!</p>
                    <style>
                        .Post__RobotsThatLearn__Video {
                            margin: 0;
                        }

                        .Post__RobotsThatLearn__Video-button span {
                            padding-top: 33vh;
                        }

                        .Post__RobotsThatLearn__Video-button span {
                            background-image: url(https://blog.openai.com/content/images/2018/06/hero-lineup-dimmed.jpg);
                            background-size: cover;
                            background-position: center center;
                        }

                        #dota-5v5-hero-video {
                            width: 100%;
                            background-repeat: no-repeat;
                            background-position: center;
                            margin-bottom: 2.5rem;
                        }

                        .ResearchPostHeader {
                            padding-bottom: 0;
                            margin-bottom: 0;
                        }

                        @media screen and (min-width: 776.25px) {
                            .ResearchPostHeader-intro {
                                width: 655px;
                                padding-left: 25px;
                            }
                        }

                        .PostContent .ResearchPostHeader-title {
                            margin-bottom: 0.4em !important;
                        }

                        .ResearchPostHeader-coverContainer {
                            display: none;
                        }
                    </style>
                    <p><img src="https://blog.openai.com/content/images/2018/06/H0A3837.jpg" alt="Players and audience of the bot playing against our human test team"><br>
                        <em>OpenAI Five playing the best OpenAI employee team. The match was commentated by professional commentator <a href="https://liquipedia.net/dota2/Blitz">Blitz</a> and OpenAI Dota team member Christy Dennison, and observed by a crowd from the community.</em></p>
                    <h1 id="theproblem">The problem</h1>
                    <p>One AI milestone is to exceed human capabilities in a complex video game like <a href="https://qz.com/1051052/deepmind-goog-and-facebook-fb-have-started-the-global-sprint-for-ai-to-beat-starcraft-ii/">StarCraft</a> or Dota. Relative
                        to previous AI milestones like <a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">Chess</a> or <a href="https://deepmind.com/research/alphago/">Go</a>, complex video games start to capture the messiness and continuous
                        nature of the real world. The hope is that systems which solve complex video games will be highly general, with applications outside of games.</p>
                    <p>Dota 2 is a real-time strategy game played between two teams of five players, with each player controlling a character called a &quot;hero&quot;. A Dota-playing AI must master the following:</p>
                    <ul>
                        <li><strong>Long time horizons.</strong> Dota games run at 30 frames per second for an average of 45 minutes, resulting in 80,000 ticks per game. Most actions (like ordering a hero to <a href="https://developer.valvesoftware.com/wiki/Dota_Bot_Scripting#UNIT_SCOPED_FUNCTIONS">move</a>                            to a location) have minor impact individually, but some individual actions like <a href="https://dota2.gamepedia.com/Town_Portal_Scroll">town portal</a> usage can affect the game strategically; some <a href="https://www.liquiddota.com/forum/dota-2-strategy/454744-a-small-primer-on-dota-2-strategy">strategies</a>                            can play out over an entire game. OpenAI Five observes every fourth frame, yielding 20,000 moves. <a href="https://blog.ebemunk.com/a-visual-look-at-2-million-chess-games/">Chess</a> usually ends before 40 moves, <a href="https://en.wikipedia.org/wiki/Go_and_mathematics#Game_tree_complexity">Go</a>                            before 150 moves, with almost every move being strategic.</li>
                        <li><strong>Partially-observed state.</strong> Units and buildings can only see the area around them. The rest of the map is covered in a fog hiding enemies and their strategies. Strong play requires making inferences based on incomplete
                            data, as well as modeling what one's opponent might be up to. Both chess and Go are full-information games.</li>
                        <li><strong>High-dimensional, continuous action space.</strong> In Dota, each hero can take dozens of actions, and many actions target either another unit or a position on the ground. We discretize the space into 170,000 possible actions
                            per hero (not all valid each tick, such as using a spell on <a href="https://dota2.gamepedia.com/Cooldown">cooldown</a>); not counting the continuous parts, there are an average of ~1,000 valid actions each tick. The average
                            <a href="https://en.wikipedia.org/wiki/Branching_factor">number of actions</a> in chess is 35; in Go, 250.</li>
                        <li><strong>High-dimensional, continuous observation space.</strong> Dota is played on a large continuous <a href="https://devilesk.com/dota2/apps/interactivemap/">map</a> containing ten heroes, dozens of buildings, dozens of <a href="https://en.wikipedia.org/wiki/Non-player_character">NPC</a>                            units, and a long tail of game features such as runes, trees, and wards. Our model observes the state of a Dota game via Valve's <a href="https://developer.valvesoftware.com/wiki/Dota_Bot_Scripting">Bot API</a> as 20,000 (mostly
                            floating-point) numbers representing all information a human is allowed to access. A chess board is naturally represented as about 70 enumeration values (a 8x8 board of 6 piece types and minor <a href="https://en.wikipedia.org/wiki/Threefold_repetition">historical</a>                            <a href="https://en.wikipedia.org/wiki/Castling">info</a>); a Go board as about 400 enumeration values (a 19x19 board of 2 piece types plus <a href="https://en.wikipedia.org/wiki/Go_(game)#Ko_rule">Ko</a>).</li>
                    </ul>
                    <p>The Dota rules are also very complex — the game has been actively developed for over a decade, with game logic implemented in hundreds of thousands of lines of code. This logic takes milliseconds per tick to execute, versus nanoseconds
                        for Chess or Go engines. The game also gets an update about once every two weeks, constantly changing the environment semantics.</p>
                    <h1 id="ourapproach">Our approach</h1>
                    <p>Our system learns using a massively-scaled version of <a href="https://blog.openai.com/openai-baselines-ppo/">Proximal Policy Optimization</a>. Both OpenAI Five and our earlier <a href="https://blog.openai.com/dota-2/">1v1 bot</a>                        learn entirely from self-play. They start with random parameters and do not use <a href="https://www.reddit.com/r/DotA2/comments/87up8k/will_open_ai_play_real_5v5_dota_at_ti_8/dwg12om/">search</a> or bootstrap from human replays.</p>
                    <table>
                        <thead>
                            <tr>
                                <th></th>
                                <th><strong>OpenAI 1v1 bot</strong></th>
                                <th><strong>OpenAI Five</strong></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>CPUs</strong></td>
                                <td>60,000 CPU cores on Azure</td>
                                <td>128,000 <a href="https://cloud.google.com/preemptible-vms/">preemptible</a> CPU cores on GCP</td>
                            </tr>
                            <tr>
                                <td><strong>GPUs</strong></td>
                                <td>256 K80 GPUs on Azure</td>
                                <td>256 P100 GPUs on GCP</td>
                            </tr>
                            <tr>
                                <td><strong>Experience collected</strong></td>
                                <td>~300 years per day</td>
                                <td>~180 years per day (~900 years per day counting each hero separately)</td>
                            </tr>
                            <tr>
                                <td><strong>Size of observation</strong></td>
                                <td>~3.3 kB</td>
                                <td>~36.8 kB</td>
                            </tr>
                            <tr>
                                <td><strong>Observations per second of gameplay</strong></td>
                                <td>10</td>
                                <td>7.5</td>
                            </tr>
                            <tr>
                                <td><strong>Batch size</strong></td>
                                <td>8,388,608 observations</td>
                                <td>1,048,576 observations</td>
                            </tr>
                            <tr>
                                <td><strong>Batches per minute</strong></td>
                                <td>~20</td>
                                <td>~60</td>
                            </tr>
                        </tbody>
                    </table>
                    <style>
                        .PostContent table {
                            width: calc(100% + 4rem);
                            max-width: calc(100% + 4rem);
                            table-layout: fixed;
                        }

                        .PostContent table tbody>tr:nth-child(odd)>td,
                        .PostContent table tbody>tr:nth-child(odd)>th {
                            background-color: #f7fbfb;
                        }
                    </style>
                    <p>RL researchers (including ourselves) have generally <a href="https://himanshusahni.github.io/2018/02/23/reinforcement-learning-never-worked.html">believed</a> that long time horizons would require fundamentally new advances, such as
                        <a href="http://www.cs.toronto.edu/~fritz/absps/dh93.pdf">hierarchical</a> <a href="https://blog.openai.com/learning-a-hierarchy/">reinforcement</a> <a href="https://einstein.ai/research/hierarchical-reinforcement-learning">learning</a>.
                        Our results suggest that we haven't been giving today's algorithms enough credit — at least when they're run at sufficient scale and with a reasonable way of <a href="#exploration">exploring</a>.</p>
                    <p>Our agent is trained to maximize the exponentially decayed sum of future rewards, weighted by an exponential decay factor called <code>γ</code>. During the latest training run of OpenAI Five, we annealed <code>γ</code> from <code>0.998</code>                        (valuing future rewards with a half-life of 46 seconds) to <code>0.9997</code> (valuing future rewards with a half-life of five minutes). For comparison, the longest horizon in the <a href="https://arxiv.org/abs/1707.06347">PPO</a>                        paper was a half-life of 0.5 seconds, the longest in the <a href="https://arxiv.org/abs/1710.02298">Rainbow</a> paper was a half-life of 4.4 seconds, and the <a href="https://arxiv.org/abs/1805.11593">Observe and Look Further</a>                        paper used a half-life of 46 seconds.</p>
                    <p>While the current version of OpenAI Five is weak at <a href="https://dota2.gamepedia.com/Creep_control_techniques#Last-hitting">last-hitting</a> (observing our test matches, the professional Dota commentator <a href="https://liquipedia.net/dota2/Blitz">Blitz</a>                        estimated it around median for Dota players), its <a href="#observations">objective prioritization</a> matches a common professional strategy. Gaining long-term rewards such as strategic map control often requires sacrificing short-term
                        rewards such as gold gained from <a href="https://dota2.gamepedia.com/Farming">farming</a>, since grouping up to attack towers takes time. This observation reinforces our belief that the system is truly optimizing over a long horizon.</p>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/UZHTNBMAfAA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    <h4 id="modelstructure">Model structure</h4>
                    <p>Each of <a href="https://d4mucfpksywv.cloudfront.net/research-covers/openai-five/network-architecture.pdf">OpenAI Five's networks</a> contain a single-layer, 1024-unit <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/#lstm-networks">LSTM</a>                        that sees the current game state (extracted from Valve's <a href="https://developer.valvesoftware.com/wiki/Dota_Bot_Scripting">Bot API</a>) and emits actions through several possible action heads. Each head has semantic meaning,
                        for example, the number of ticks to delay this action, which action to select, the X or Y coordinate of this action in a grid around the unit, etc. Action heads are computed independently.</p>
                    <p><em>Interactive demonstration of the observation space and action space used by OpenAI Five. OpenAI Five views the world as a list of 20,000 numbers, and takes an action by emitting a list of 8 enumeration values. Select different actions and targets to understand how OpenAI Five encodes each action, and how it observes the world. The image shows the scene as a human would see it.</em></p>
                </section>
                <link href="https://d4mucfpksywv.cloudfront.net/research-covers/openai-five/css/style.css" rel="stylesheet">
                <div class="diagram-container">
                    <div id="dota-diagram"></div>
                </div>
                <script src="https://d4mucfpksywv.cloudfront.net/research-covers/openai-five/scripts.v1.min.js" type="text/javascript"></script>
                <section class="Post-inner PostContent post-content research-release-post" id="content">
                    <p>OpenAI Five can react to missing pieces of state that correlate with what it does see. For example, until recently OpenAI Five's observations did not include <a href="https://dota2.gamepedia.com/Sniper#Abilities">shrapnel</a> zones
                        (areas where projectiles rain down on enemies), which humans see on screen. However, we observed OpenAI Five learning to walk out of (though not avoid entering) active shrapnel zones, since it could see its health decreasing.</p>
                    <h4 id="exploration">Exploration</h4>
                    <p>Given a learning algorithm capable of handling long horizons, we still need to explore the environment. Even with our <a href="#restricted">restrictions</a>, there are hundreds of items, dozens of buildings, spells, and unit types,
                        and a long tail of game mechanics to learn about — many of which yield powerful combinations
                        <!--TODO: link to video of combos-->. It's not easy to explore this combinatorially-vast space efficiently.</p>
                    <p>OpenAI Five learns from self-play (starting from random weights), which provides a natural curriculum for exploring the environment. To avoid &quot;strategy collapse&quot;, the agent trains 80% of its games against itself and the other
                        20% against its past selves. In the first games, the heroes walk aimlessly around the map. After several hours of training, concepts such as <a href="https://www.reddit.com/r/DotA2/comments/17fj2y/laning_101/">laning</a>, <a href="https://dota2.gamepedia.com/Farming">farming</a>,
                        or fighting over <a href="https://pvgna.com/dota2/paths/how-to-master-mid-lane">mid</a> emerge. After several days, they consistently adopt basic human strategies: attempt to steal <a href="https://dota2.gamepedia.com/Bounty_Rune">Bounty</a>                        runes from their opponents, walk to their <a href="https://dota2.gamepedia.com/Buildings#Towers">tier one</a> towers to farm, and rotate heroes around the map to gain lane advantage. And with further training, they become proficient
                        at high-level strategies like <a href="https://www.reddit.com/r/DotA2/comments/4iyr00/how_do_you_counter_a_5man_early_game_push_strat/">5-hero push</a>.</p>
                    <p>In March 2017, our first <a href="https://www.youtube.com/watch?v=5Fv2c4aNS2w&amp;feature=youtu.be">agent</a> defeated bots but got confused against humans. To force exploration in strategy space, during training (and only during training)
                        we randomized the properties (health, speed, start level, etc.) of the units, and it began beating humans. Later on, when a test player was consistently beating our 1v1 bot, we increased our training randomizations and the test
                        player started to lose. (Our robotics team concurrently applied similar randomization techniques to <a href="https://blog.openai.com/generalizing-from-simulation/">physical</a> <a href="https://blog.openai.com/spam-detection-in-the-physical-world/">robots</a>                        to transfer from simulation to the real world.)</p>
                    <p>OpenAI Five uses the randomizations we wrote for our 1v1 bot. It also uses a new &quot;lane assignment&quot; one. At the beginning of each training game, we randomly &quot;assign&quot; each hero to some subset of <a href="https://dota2.gamepedia.com/Lane">lanes</a>                        and penalize it for straying from those lanes until a randomly-chosen time in the game.</p>
                    <p>Exploration is also helped by a good reward. <a href="https://gist.github.com/dfarhi/66ec9d760ae0c49a5c492c9fae93984a">Our reward</a> consists mostly of metrics humans track to decide how they're doing in the game: net worth, kills,
                        deaths, assists, last hits, and the like. We postprocess each agent's reward by subtracting the other team's average reward to prevent the agents from finding positive-sum situations.</p>
                    <p>We hardcode item and skill builds (originally written for our <a href="https://blog.openai.com/more-on-dota-2/#infrastructure">scripted</a> baseline), and choose which of the builds to use at random. <a href="https://dota2.gamepedia.com/Courier">Courier</a>                        management is also imported from the scripted baseline.</p>
                    <h4 id="coordination">Coordination</h4>
                    <p>OpenAI Five does not contain an explicit communication channel between the heroes' neural networks. Teamwork is controlled by a hyperparameter we dubbed &quot;team spirit&quot;. Team spirit ranges from 0 to 1, putting a weight on how
                        much each of OpenAI Five's heroes should care about its individual reward function versus the average of the team's reward functions. We anneal its value from 0 to 1 over training.</p>
                    <h4 id="rapid">Rapid</h4>
                    <img class="Dota-Minigraph" src="https://blog.openai.com/content/images/2018/06/rapid@2x.png" alt="OpenAI Rapid" />
                    <p>Our system is implemented as a general-purpose RL training system called Rapid, which can be applied to any <a href="https://github.com/openai/gym">Gym</a> environment. We've used Rapid to solve other problems at OpenAI, including
                        <a href="https://blog.openai.com/competitive-self-play/">Competitive Self-Play</a>.</p>
                    <p><img src="https://blog.openai.com/content/images/2018/06/rapid-architecture@2x--1-.png" alt="rapid-architecture@2x--1-"></p>
                    <p>The training system is separated into <em>rollout</em> workers, which run a copy of the game and an agent gathering experience, and <em>optimizer</em> nodes, which perform synchronous gradient descent across a fleet of GPUs. The rollout
                        workers sync their experience through Redis to the optimizers. Each experiment also contains workers evaluating the trained agent versus reference agents, as well as monitoring software such as <a href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard">TensorBoard</a>,
                        <a href="https://sentry.io/welcome/">Sentry</a>, and <a href="https://grafana.com/">Grafana</a>.</p>
                    <img class="Dota-Minigraph" src="https://blog.openai.com/content/images/2018/06/gpu-synchronization-time-small@2x.png" />
                    <p>During synchronous gradient descent, each GPU computes a gradient on its part of the batch, and then the gradients are globally averaged. We originally used <a href="https://en.wikipedia.org/wiki/Message_Passing_Interface">MPI's</a>                        <a href="http://www.mcs.anl.gov/research/projects/mpi/mpi-standard/mpi-report-1.1/node82.htm">allreduce</a> for averaging, but now use our own <a href="https://developer.nvidia.com/nccl">NCCL2</a> wrappers that parallelize GPU
                        computations and network data transfer.<br> The latencies for synchronizing 58MB of data (size of OpenAI Five's parameters) across different numbers of GPUs are shown on the right. The latency is low enough to be largely masked
                        by GPU computation which runs in parallel with it.</p>
                    <p>We've implemented Kubernetes, Azure, and GCP backends for Rapid.</p>
                    <h1 id="thegames">The games</h1>
                    <p>Thus far OpenAI Five has played (with our <a href="#restricted">restrictions</a>) versus each of these teams:</p>
                    <ol>
                        <li>Best OpenAI employee team: 2.5k <a href="https://dota2.gamepedia.com/Matchmaking_Rating">MMR</a> (46th percentile)</li>
                        <li>Best audience players watching OpenAI employee match (including Blitz, who commentated the first OpenAI employee match): 4-6k MMR (90th-99th percentile), though they'd never played as a team.</li>
                        <li>Valve employee team: 2.5-4k MMR (46th-90th percentile).</li>
                        <li>Amateur team: 4.2k MMR (93rd percentile), trains as a team.</li>
                        <li>Semi-pro team: 5.5k MMR (99th percentile), trains as a team.</li>
                    </ol>
                    <p>The April 23rd version of OpenAI Five was the first to beat our scripted baseline. The May 15th version of OpenAI Five was evenly matched versus team 1, winning one game and losing another. The June 6th version of OpenAI Five decisively
                        won all its games versus teams 1-3. We set up informal <a href="https://www.reddit.com/r/DotA2/comments/3s9zet/what_is_a_scrim/">scrims</a> with teams 4 &amp; 5, expecting to lose soundly, but OpenAI Five won two of its first three
                        games versus both.</p>
                    <p><img src="https://blog.openai.com/content/images/2018/06/195A8963_cropped.jpg" alt="195A8963_cropped"></p>
                    <blockquote>
                        <p>The teamwork aspect of the bot was just overwhelming. It feels like five selfless players that know a good general strategy.</p>
                        <p>— Blitz</p>
                    </blockquote>
                    <p><a name="observations" id="observations"></a>We observed that OpenAI Five:</p>
                    <ul>
                        <li>Repeatedly sacrificed its own <a href="https://dota2.gamepedia.com/Lane">safe lane</a> (top lane for dire; bottom lane for radiant) in exchange for controlling the enemy's safe lane, forcing the fight onto the side that is harder
                            for their opponent to defend. This strategy emerged in the professional scene in the last few years, and is now considered to be the prevailing tactic. Blitz commented that he only learned this after eight years of play, when
                            <a href="https://liquipedia.net/dota2/Team_Liquid">Team Liquid</a> told him about it.</li>
                        <li><img class="Dota-Minigraph" src="https://blog.openai.com/content/images/2018/06/ganking-2.gif" />Pushed the <a href="https://purgegamers.true.io/purge/phases-of-the-game/">transitions</a> from early- to mid-game faster than its
                            opponents. It did this by: (1) setting up successful <a href="https://dota2.gamepedia.com/Ganking">ganks</a> (when players move around the map to ambush an enemy hero — see animation) when players overextended in their lane,
                            and (2) by grouping up to take towers before the opponents could organize a counterplay.
                            <div style="clear:both"></div>
                        </li>
                        <li>Deviated from current <a href="https://liquipedia.net/dota2/Metagame">playstyle</a> in a few areas, such as giving <a href="https://dota2.gamepedia.com/Role#Support">support</a> heroes (which usually do not take priority for resources)
                            lots of early experience and gold. OpenAI Five's prioritization allows for its damage to peak sooner and push its advantage harder, winning team fights and capitalizing on mistakes to ensure a fast win.</li>
                    </ul>
                    <p><img src="https://blog.openai.com/content/images/2018/06/_H0A3928.jpg" alt="_H0A3928"><br>
                        <em>Trophies awarded after the match between the best players at OpenAI and our bot team. One trophy for the humans, one trophy for the bots (represented by Susan Zhang from our team!)</em></p>
                    <h1 id="differencesversushumans">Differences versus humans</h1>
                    <p>OpenAI Five is given access to the same information as humans, but instantly sees data like positions, healths, and item inventories that humans have to check manually. Our method isn't fundamentally tied to observing state, but just
                        rendering pixels from the game would require thousands of GPUs.</p>
                    <p>OpenAI Five averages around 150-170 actions per minute (and has a theoretical maximum of 450 due to observing every 4th frame). Frame-perfect timing, while <a href="https://www.reddit.com/r/DotA2/comments/493wib/frameperfect_stun_by_swindle_on_enchantress_in_eg/">possible</a>                        for skilled players, is trivial for OpenAI Five. OpenAI Five has an average reaction time of 80ms, which is faster than humans.</p>
                    <p>These differences matter most in 1v1 (where our bot had a reaction time of 67ms), but the playing field is relatively equitable as we've seen humans learn from and adapt to the bot. Dozens of <a href="https://www.reddit.com/r/DotA2/comments/6yp5ug/black_just_killed_open_ai/">professionals</a>                        <a href="https://www.reddit.com/r/DotA2/comments/6wqf5x/bulldog_gets_jebaited_hard_by_openai_bot/">used</a> our 1v1 bot for <a href="https://www.youtube.com/watch?v=DQ3fPS9345A">training</a> in the months after last year's <a href="https://en.wikipedia.org/wiki/The_International_(Dota_2)">TI</a>.
                        According to Blitz, the 1v1 bot has changed the way people think about 1v1s (the bot adopted a fast-paced playstyle, and everyone has now adapted to keep up).</p>
                    <h1 id="surprisingfindings">Surprising findings</h1>
                    <style>
                        img.Dota-Minigraph,
                        video.Dota-Minigraph {
                            float: right;
                            display: inline;
                            width: 40%;
                            max-width: none;
                            padding: 0.5rem 0;
                            position: inherit;
                            transform: none;
                        }
                    </style>
                    <ul>
                        <li><img class="Dota-Minigraph" src="https://blog.openai.com/content/images/2018/06/sparse-vs-dense-small@2x.png" alt="Sparse vs Dense rewards learning curves, showing dense reaching an equivalent level of performance faster." /><strong>Binary rewards can give good performance.</strong>                            Our 1v1 model had a shaped reward, including rewards for last hits, kills, and the like. We ran an experiment where we only rewarded the agent for winning or losing, and it trained an order of magnitude slower and somewhat
                            plateaued in the middle, in contrast to the smooth learning curves we usually see. The experiment ran on 4,500 cores and 16 k80 GPUs, training to the level of semi-pros (70 <a href="https://en.wikipedia.org/wiki/TrueSkill">TrueSkill</a>)
                            rather than 90 TrueSkill of our best 1v1 bot).</li>
                        <li><strong>Creep blocking can be learned from scratch.</strong> For 1v1, we learned <a href="https://blog.openai.com/more-on-dota-2/#thetask">creep blocking</a> using traditional RL with a "creep block" reward. One of our team members
                            left a 2v2 model training when he went on vacation (proposing to his now wife!), intending to see how much longer training would boost performance. To his surprise, the model had <a href="https://s3-us-west-2.amazonaws.com/openai-assets/dota_2018/cm_creepblock.mp4">learned to creep block</a>                            without any special guidance or reward.</li>
                        <li><img class="Dota-Minigraph" src="https://blog.openai.com/content/images/2018/06/bug-comparison-small@2x.png" alt="Comparison of learning curves before and after bugfixes, showing how fixing bugs increases learning speed." /><strong>We're still fixing bugs.</strong>                            The chart shows a training run of the code that defeated amateur players, compared to a version where we simply fixed a number of bugs, such as rare crashes during training, or a bug which resulted in a large negative reward
                            for reaching level 25. It turns out it's possible to beat good humans while still hiding serious bugs!</li>
                    </ul>
                    <p><img src="https://blog.openai.com/content/images/2018/06/group-laptop.jpg" alt="group-laptop"><br>
                        <em>A subset of the OpenAI Dota team, holding the laptop that <a href="https://blog.openai.com/dota-2/">defeated</a> the world's top professionals at Dota 1v1 at The International last year.</em></p>
                    <h1 id="whatsnext">What's next</h1>
                    <p>Our team is focused on making our August goal. We don't know if it will be achievable, but we believe that with hard work (and some luck) we have a real shot.</p>
                    <p>This post described a snapshot of our system as of June 6th. We'll release updates along the way to surpassing human performance and write a report on our final system once we complete the project. Please join us on July 28th <a href="https://www.twitch.tv/openai">virtually</a>                        or <a href="https://www.eventbrite.com/e/openai-dota-5v5-match-tickets-47144438284">in person</a>, when we'll play a team of top players!</p>
                    <p>Our underlying motivation reaches beyond Dota. Real-world AI deployments will need to deal with the <a href="#theproblem">challenges</a> raised by Dota which are not reflected in Chess, Go, Atari games, or Mujoco benchmark tasks. Ultimately,
                        we will measure the success of our Dota system in its application to real-world tasks. If you'd like to be part of what comes next, we're <a href="https://openai.com/jobs/">hiring</a>!</p>
                    <script>
                        // From https://stackoverflow.com/questions/2450954/how-to-randomize-shuffle-a-javascript-array
                        function teamblock(team, cls) {
                            function shuffle(array) {
                                var currentIndex = array.length,
                                    temporaryValue, randomIndex;
                                // While there remain elements to shuffle...
                                while (0 !== currentIndex) {
                                    // Pick a remaining element...
                                    randomIndex = Math.floor(Math.random() * currentIndex);
                                    currentIndex -= 1;
                                    // And swap it with the current element.
                                    temporaryValue = array[currentIndex];
                                    array[currentIndex] = array[randomIndex];
                                    array[randomIndex] = temporaryValue;
                                }
                                return array;
                            }
                            team = shuffle(team);
                            var items = team.map(function(n) {
                                return "<li class='Page-Event__Team-individual'>" + n + "</li>";
                            }).join("");
                            var teamblock = "<ul class='Page-Event__Team " + cls + "'>" + items + "</ul>";
                            return teamblock
                        }
                        var alpha = ["Brooke Chan", "Christy Dennison", "David Farhi", "Filip Wolski", "Greg Brockman", "Henrique Pondé", "Jakub Pachocki", "Jie Tang", "Jonathan Raiman", "Michael Petrov", "Przemysław Dębiak", "Susan Zhang", "Szymon Sidor", "Rafał Józefowicz"];
                        var beta = ["Quirin Fischer", "Christopher Hesse", "Shariq Hashme", "Ilya Sutskever", "Alec Radford", "Scott Gray", "Jack Clark", "Paul Christiano", "David Luan", "Christopher Berner", "Eric Sigler", "Jonas Schneider", "Larissa Schiavo", "Diane Yoon", "John Schulman"]
                        var byline = "<span class='PostFooter-authors--label'>Built by a team of researchers and engineers at OpenAI (order randomized each pageload).</span>";
                        document.addEventListener("DOMContentLoaded", function(event) {
                            document.querySelector(".PostFooter-authors").innerHTML = byline;
                            document.querySelector(".PostFooter").innerHTML += "<div class='PostFooter-authors dota-5v5-authors'>" + teamblock(alpha, "") + teamblock(beta, " Page-Event__Team-beta") + "</div>";
                        });
                    </script>
                    <style>
                        .PostFooter {
                            flex-wrap: wrap;
                        }

                        .PostFooter-authors {
                            width: 50%;
                        }

                        .Page-Event__Team-individual {
                            //font-size: 1.8em;
                            line-height: 1.28em;
                            list-style: none; //width: 50%;
                            text-align: center;
                            padding: .5rem;
                            font-weight: 500; //color: #f8dc57;
                        }

                        .Page-Event__Team {
                            margin: 0;
                            padding: 0px;
                            max-width: 400px;
                            margin: 0.5rem auto;
                            display: -ms-flexbox;
                            display: flex;
                            -ms-flex-wrap: wrap;
                            flex-wrap: wrap;
                        }

                        .Page-Event__Team-beta {
                            margin-top: 3.5rem;
                        }
                    </style>
                    <hr/>
                    <div style="font-size: 85%">
                        <p><a id="restricted" name="restricted"></a>[1] Current set of restrictions:</p>
                        <ul>
                            <li><em>Mirror match of <a href="https://dota2.gamepedia.com/Necrophos">Necrophos</a>, <a href="https://dota2.gamepedia.com/Sniper">Sniper</a>, <a href="https://dota2.gamepedia.com/Viper">Viper</a>, <a href="https://dota2.gamepedia.com/Crystal_Maiden">Crystal Maiden</a>, and <a href="https://dota2.gamepedia.com/Lich">Lich</a></em></li>
                            <li><em>No <a href="https://www.thescoreesports.com/dota2/news/13481-a-basic-guide-to-warding-in-dota-2">warding</a></em></li>
                            <li><em>No <a href="https://dota2.gamepedia.com/Roshan">Roshan</a></em></li>
                            <li><em>No <a href="https://dota2.gamepedia.com/Invisibility">invisibility</a> (consumables and relevant items)</em></li>
                            <li><em>No <a href="https://dota2.gamepedia.com/Summons">summons</a>/<a href="https://dota2.gamepedia.com/Illusions">illusions</a></em></li>
                            <li><em>No <a href="https://dota2.gamepedia.com/Divine_Rapier">Divine Rapier</a>, <a href="https://dota2.gamepedia.com/Bottle">Bottle</a>, <a href="https://dota2.gamepedia.com/Quelling_Blade">Quelling Blade</a>, <a href="https://dota2.gamepedia.com/Boots_of_Travel">Boots of Travel</a>, <a href="https://dota2.gamepedia.com/Tome_of_Knowledge">Tome of Knowledge</a>, <a href="https://dota2.gamepedia.com/Infused_Raindrop">Infused Raindrop</a></em></li>
                            <li><em>5 invulnerable couriers, no exploiting them by scouting or tanking</em></li>
                            <li><em>No <a href="https://dota2.gamepedia.com/Scan">Scan</a></em></li>
                        </ul>
                        <p>The hero set restriction makes the game very different from how Dota is played at world-elite level (i.e. <a href="https://dota2.gamepedia.com/Game_modes#Captains_Mode">Captains Mode</a> drafting from all 100+ heroes). However,
                            the difference from regular &quot;public&quot; games (<a href="https://dota2.gamepedia.com/Game_modes#All_Pick">All Pick</a> / <a href="https://dota2.gamepedia.com/Game_modes#Random_Draft">Random Draft</a>) is smaller.</p>
                        <p>Most of the restrictions come from remaining aspects of the game we haven't integrated yet. Some restrictions, in particular wards and Roshan, are central components of professional-level play. We're working to add these as soon
                            as possible.</p>
                        <p>[2] Thanks to the following for feedback on drafts of this post: Alexander Lavin, Andrew Gibiansky, Anna Goldie, Azalia Mirhoseini, Catherine Olsson, David Dohan, David Ha, Denny Britz, Erich Elsen, James Bradbury, John Miller,
                            Luke Metz, Maddie Hall, Miles Brundage, Nelson Elhage, Ofir Nachum, Pieter Abbeel, Rumen Hristov, Shubho Sengupta, Solomon Boulos, Stephen Merity, Tom Brown, Zak Stone</p>
                    </div>
                    <script>
                        var links = document.links;
                        var article = document.body.querySelector("article");
                        for (var i = 0, linksLength = links.length; i < linksLength; i++) {
                            if (links[i].hostname != window.location.hostname && article.contains(links[i])) {
                                links[i].target = '_blank';
                            }
                        }
                    </script>
                    <!-- for video player -->
                    <script src="https://www.youtube.com/iframe_api"></script>
                    <meta name="twitter:description" content="Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2. While today we play with restrictions, we aim to beat a team of top professionals at The International in August subject only to a limited set of heroes."
                    />
                    <meta name="twitter:card" content="player" />
                    <meta name="twitter:image" content="https://blog.openai.com/content/images/2018/06/christy-v2-square.jpg" />
                    <meta name="twitter:player" content="https://www.youtube.com/embed/eHipy_j29Xw?rel=0&showinfo=0" />
                    <meta name="twitter:player:width" content="600" />
                    <meta name="twitter:player:height" content="336" />
                    </div>
                </section>
                <footer class="PostFooter">
                    <div class="PostFooter-authors">
                        <span class="PostFooter-authors--label">By</span>
                    </div>
                </footer>
            </article>
        </div>
    </main>
    <script type="text/javascript" src="https://blog.openai.com/assets/js/app.js?v=f5ebf2b765"></script>
    <svg width="0" height="0" viewBox="0 0 330 418" style='visibility:hidden;width:0;height:0;display:block;'>
  <filter id="f1" x="-50%" y="-50%" width="200%" height="200%">
    <feGaussianBlur in="SourceGraphic" stdDeviation="30" />
  </filter>
  <defs>
    <linearGradient id="blue">
      <stop offset="0" stop-color="rgb(94,33,217)" />
      <stop offset="1" stop-color="rgb(18,165,226)" />
    </linearGradient>
    <linearGradient id="blue_green">
      <stop offset="0" stop-color="rgb(47,134,215)"/>
      <stop offset="1" stop-color="rgb(28,245,186)"/>
    </linearGradient>
    <linearGradient id="cyan">
      <stop offset="0" stop-color="rgb(64,100,216)"/>
      <stop offset="1" stop-color="rgb(74,216,221)"/>
    </linearGradient>
    <linearGradient id="purple">
      <stop offset="0" stop-color="rgb(90,64,216)"/>
      <stop offset="1" stop-color="rgb(216,74,221)"/>
    </linearGradient>
    <linearGradient id="red">
      <stop offset="0" stop-color="rgb(183,24,102)"/>
      <stop offset="1" stop-color="rgb(235,52,52)"/>
    </linearGradient>
    <linearGradient id="orange">
      <stop offset="0" stop-color="rgb(211,56,56)"/>
      <stop offset="1" stop-color="rgb(242,153,38)"/>
    </linearGradient>
    <linearGradient id="yellow">
      <stop offset="0" stop-color="rgb(232,91,6)"/>
      <stop offset="1" stop-color="rgb(229,231,42)"/>
    </linearGradient>
    <linearGradient id="green">
      <stop offset="0" stop-color="rgb(13,163,130)"/>
      <stop offset="1" stop-color="rgb(103,228,78)"/>
    </linearGradient>
    <linearGradient id="black">
      <stop offset="0" stop-color="rgb(0,0,0)"/>
      <stop offset="1" stop-color="rgb(38,38,38)"/>
    </linearGradient>
    <linearGradient id="slate-dark">
      <stop offset="0" stop-color="rgb(34,34,34)"/>
      <stop offset="1" stop-color="rgb(69,69,77)"/>
    </linearGradient>
    <linearGradient id="slate-mid">
      <stop offset="0" stop-color="rgb(59,62,76)"/>
      <stop offset="1" stop-color="rgb(102,102,120)"/>
    </linearGradient>
    <linearGradient id="slate-light">
      <stop offset="0" stop-color="rgb(137,137,155)"/>
      <stop offset="1" stop-color="rgb(181,181,196)"/>
    </linearGradient>
    <!-- Outer shape -->
    <symbol id="outer">
      <path d="M268.7 12c-10.16-4.21-26.79-4.21-37 0l-137 56.74C84.61 73 72.85 84.71 68.64 94.87l-56.74 137c-4.21 10.16-4.21 26.79 0 37l56.74 137c4.21 10.16 16 21.92 26.13 26.13l137 56.74c10.16 4.21 26.79 4.21 37 0l137-56.74c10.16-4.21 21.92-16 26.13-26.13l56.74-137c4.21-10.16 4.21-26.79 0-37l-56.74-137c-4.21-10.16-16-21.92-26.13-26.13z" />
    </symbol>
    <!-- Inner shape -->
    <symbol id="inner">
      <path d="M250.22 56.28l-137.2 56.84-56.84 137.21 56.84 137.21 137.21 56.83 137.2-56.84 56.84-137.21-56.84-137.2-137.21-56.84z"/>
    </symbol>
    <mask id="outerMask" maskUnits="userSpaceOnUse" x="0" y="0" width="500" height="500">
      <rect x="0" y="0" width="500" height="500" fill="white"/>
      <use filter="url(#f1)" xlink:href="#outer" />
    </mask>
    <mask id="outlineMask" maskUnits="userSpaceOnUse" x="0" y="0" width="500" height="500">
      <use fill="white" xlink:href="#outer" />
      <use fill="black" xlink:href="#inner" />
    </mask>
  </defs>
  <symbol id="circle">
    <path class="cls-1" d="M46.633,169.834A171,171,0,1,1-162.8,290.749,171,171,0,0,1,46.633,169.834Z"/>
    <circle class="cls-2" cx="250.625" cy="98.984" r="171.063"/>
  </symbol>
  <symbol id="hexagon">
    <path d="M103.728-104.851a20.335,20.335,0,0,0-13.505,0L-16.926-60.458a20.338,20.338,0,0,0-9.549,9.55L-70.851,56.249a20.338,20.338,0,0,0,0,13.506L-26.458,176.9a20.343,20.343,0,0,0,9.551,9.55L90.249,230.828a20.336,20.336,0,0,0,13.505,0L210.9,186.435a20.337,20.337,0,0,0,9.549-9.55L264.828,69.729a20.336,20.336,0,0,0,0-13.505L220.435-50.926a20.337,20.337,0,0,0-9.551-9.549Z"/>
    <path d="M186.713,201.118a20.332,20.332,0,0,0-13.506,0l-107.16,44.4a20.342,20.342,0,0,0-9.55,9.551L12.117,362.232a20.341,20.341,0,0,0,0,13.507L56.515,482.9a20.335,20.335,0,0,0,9.551,9.55l107.166,44.38a20.334,20.334,0,0,0,13.507,0l107.159-44.4a20.339,20.339,0,0,0,9.55-9.552l44.38-107.166a20.338,20.338,0,0,0,0-13.506l-44.4-107.16a20.343,20.343,0,0,0-9.552-9.55Z"/>
  </symbol>
  <symbol id="square">
    <path d="M184.988,276.989a14.03,14.03,0,0,1,0,19.774L38.917,442.917a14.011,14.011,0,0,1-19.762,0L-126.916,296.762a14.027,14.027,0,0,1,0-19.773L19.155,130.835a14.009,14.009,0,0,1,19.762,0Z" transform="translate(0 -47)"/>
    <path d="M464.677,206.029a14.843,14.843,0,0,1,0,20.932L309.948,381.673a14.846,14.846,0,0,1-20.933,0L134.286,226.96a14.844,14.844,0,0,1,0-20.931L289.015,51.317a14.847,14.847,0,0,1,20.934,0Z" transform="translate(0 -47)"/>
  </symbol>
  <symbol id="triangle">
    <path d="M71.037-26.913c-4.7-8.144-12.378-8.144-17.074,0L-130,292.192c-4.695,8.144-.854,14.808,8.537,14.808H246.462c9.391,0,13.232-6.664,8.537-14.808Z"/>
    <path d="M305-.476C299.5-10,290.5-10,285-.476L69.5,372.683C64,382.208,68.5,390,79.5,390h431c11,0,15.5-7.792,10-17.317Z"/>
  </symbol>
  <symbol id="hexagon-icon">
    <g mask="url(#outlineMask)">
      <rect mask="url(#outerMask)"  x="-50%" y="-50%" width="200%" height="200%" fill="black"/>
      <rect mask="url(#outerMask)"  x="-50%" y="-50%" width="200%" height="200%" fill="black"/>
      <rect mask="url(#outerMask)"  x="-50%" y="-50%" width="200%" height="200%" fill="black"/>
    </g>
  </symbol>
</svg>
</body>
<style>
    .PostHeader {
        background: transparent !important;
        text-align: left;
        margin-bottom: 0;
    }

    .PostHeader-inner {
        padding: calc(35px + 3rem) 25px 3rem;
    }

    #content {
        margin-top: 40px;
    }

    .PostHeader-title {
        color: inherit;
    }
</style>
<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "Article",
        "publisher": {
            "@type": "Organization",
            "name": "OpenAI Blog",
            "logo": {
                "@type": "ImageObject",
                "url": "https://blog.openai.com/content/images/2017/03/twitter.png",
                "width": 60,
                "height": 60
            }
        },
        "author": {
            "@type": "Person",
            "name": "OpenAI",
            "url": "https://blog.openai.com/author/openai/",
            "sameAs": []
        },
        "headline": "OpenAI Five",
        "url": "https://blog.openai.com/openai-five/",
        "datePublished": "2018-06-25T14:00:10.000Z",
        "dateModified": "2018-06-25T20:53:45.000Z",
        "image": {
            "@type": "ImageObject",
            "url": "https://blog.openai.com/content/images/2018/06/dota-card-2.jpg",
            "width": 1200,
            "height": 675
        },
        "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://blog.openai.com/"
        }
    }
</script>

</html>